import QuizEmbed from '@/components/QuizEmbed';
import ProgressTracker from '@/components/ProgressTracker';

# Module 2: Context Expansion

<ProgressTracker moduleId="module-2" />

**Module Duration:** 90 minutes  
**Source Material:** [davidkimai/Context-Engineering](https://github.com/davidkimai/Context-Engineering)
- Part 1: 00_foundations/02_molecules_few_shot.md
- Part 2: 00_foundations/03_cells_memory.md

---

# Part 1: Molecules - Combining Prompts with Examples

> "The whole is greater than the sum of its parts." — Aristotle

## From Atoms to Molecules

In the previous section, we explored **atomic prompts** — single instructions that form the basic unit of LLM interaction. Now we'll combine these atoms into **molecules**: structured contexts that include examples and patterns for the model to follow.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  MOLECULE = [INSTRUCTION] + [EXAMPLES] + [CONTEXT] + [NEW INPUT]            │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

This molecular approach leverages a powerful capability of LLMs: **few-shot learning**.

## Few-Shot Learning: Teaching by Example

Few-shot learning is when we provide examples of the desired input-output pattern, allowing the model to recognize and continue the pattern.

```
┌───────────────────────────────────────────────────────────────────────┐
│ Input: "Paris"                                                        │
│ Output: "Paris is the capital of France."                             │
│                                                                       │
│ Input: "Tokyo"                                                        │
│ Output: "Tokyo is the capital of Japan."                              │
│                                                                       │
│ Input: "Ottawa"                                                       │
│ Output: ?                                                             │
└───────────────────────────────────────────────────────────────────────┘
```

The model recognizes the pattern and completes it: "Ottawa is the capital of Canada."

## The Molecular Advantage: Measurable Improvements

Let's compare atomic vs. molecular approaches to the same task:

```
┌───────────────────────────────────────┬──────────────────────────────────────┐
│ ATOMIC APPROACH                       │ MOLECULAR APPROACH                   │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ "Classify this review as positive     │ "Classify the sentiment of reviews.  │
│  or negative:                         │                                      │
│                                       │ Review: 'The food was amazing!'      │
│  'The service was terrible and        │ Sentiment: Positive                  │
│   the food was cold.'"                │                                      │
│                                       │ Review: 'Waited 30 minutes and       │
│                                       │  the food was cold.'                 │
│                                       │ Sentiment: Negative                  │
│                                       │                                      │
│                                       │ Review: 'The service was terrible    │
│                                       │  and the food was cold.'"            │
│                                       │ Sentiment:                           │
└───────────────────────────────────────┴──────────────────────────────────────┘
```

The molecular approach typically achieves:
- Higher accuracy (10-30% improvement on many tasks)
- Greater consistency (lower variance in outputs)
- Better format adherence
- Clearer handling of edge cases

<QuizEmbed 
  moduleId="module-2" 
  section="few-shot-basics"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'What is few-shot learning in the context of LLMs?',
      options: {
        A: 'Training a model with limited data',
        B: 'Providing examples of desired input-output patterns for the model to recognize and continue',
        C: 'Using multiple models simultaneously',
        D: 'Reducing the number of tokens in prompts'
      },
      correct: 'B',
      hint: 'Think about teaching by example within a single prompt',
      explanation: 'Few-shot learning involves providing examples of the desired input-output pattern in the prompt, allowing the model to recognize and continue the pattern without additional training.'
    },
    {
      difficulty: 'medium',
      question: 'According to the content, what is the typical accuracy improvement when using molecular (few-shot) approaches compared to atomic prompts?',
      options: {
        A: '5-10% improvement',
        B: '10-30% improvement',
        C: '30-50% improvement',
        D: '50-70% improvement'
      },
      correct: 'B',
      hint: 'Look at the "Molecular Advantage" section',
      explanation: 'The content states that molecular approaches typically achieve 10-30% improvement in accuracy on many tasks, along with greater consistency and better format adherence.'
    },
    {
      difficulty: 'hard',
      question: 'What does the equation MOLECULE = [INSTRUCTION] + [EXAMPLES] + [CONTEXT] + [NEW INPUT] represent?',
      options: {
        A: 'A mathematical formula for calculating prompt efficiency',
        B: 'The structure of a molecular prompt that combines multiple elements',
        C: 'A training methodology for LLMs',
        D: 'The order of operations in multi-agent systems'
      },
      correct: 'B',
      hint: 'Consider what components make up a molecular prompt structure',
      explanation: 'This equation represents the structural composition of a molecular prompt, showing how it combines instructions, examples, context, and new input to create a more effective prompt than atomic instructions alone.'
    }
  ]}
/>

## Designing Effective Molecular Templates

The structure of your molecular context matters greatly. Here are common patterns:

```
┌─────────────────────────┐  ┌───────────────────┐  ┌───────────────────┐
│ PREFIX-SUFFIX           │  │ INPUT-OUTPUT PAIRS│  │ CHAIN-OF-THOUGHT  │
├─────────────────────────┤  ├───────────────────┤  ├───────────────────┤
│ <instruction>           │  │ <instruction>     │  │ <instruction>     │
│                         │  │                   │  │                   │
│ <example1> → <result1>  │  │ Input: <example1> │  │ Input: <example1> │
│                         │  │ Output: <result1> │  │ Thinking: <step1> │
│ <example2> → <result2>  │  │                   │  │           <step2> │
│                         │  │ Input: <example2> │  │ Output: <result1> │
│ <new_input> →           │  │ Output: <result2> │  │                   │
└─────────────────────────┘  │                   │  │ Input: <example2> │
                             │ Input: <new_input>│  │ Thinking: <step1> │
                             │ Output:           │  │           <step2> │
                             └───────────────────┘  │ Output: <result2> │
                                                    │                   │
                                                    │ Input: <new_input>│
                                                    │ Thinking:         │
                                                    └───────────────────┘
```

Each template has strengths for different tasks:
- **Prefix-Suffix**: Simplest, works well for straightforward tasks
- **Input-Output Pairs**: Clear demarcation, good for structured data
- **Chain-of-Thought**: Exposes reasoning steps, best for complex tasks

## The Science of Example Selection

Not all examples are created equal. When choosing examples for your molecular context:

```
┌──────────────────────────────────────────────────────────────┐
│ EXAMPLE SELECTION STRATEGIES                                 │
├──────────────────────────────────────────────────────────────┤
│ ✓ Cover diverse cases to show range                          │
│ ✓ Include edge cases that clarify boundaries                 │
│ ✓ Order from simple to complex when possible                 │
│ ✓ Use recent or common examples (recency and frequency bias) │
│ ✓ Include near-misses to establish precise boundaries        │
└──────────────────────────────────────────────────────────────┘
```

<QuizEmbed 
  moduleId="module-2" 
  section="templates-selection"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'Which molecular template is best for complex tasks that require exposing reasoning steps?',
      options: {
        A: 'Prefix-Suffix template',
        B: 'Input-Output Pairs template',
        C: 'Chain-of-Thought template',
        D: 'All templates work equally well'
      },
      correct: 'C',
      hint: 'Consider which template shows the thinking process',
      explanation: 'The Chain-of-Thought template is best for complex tasks because it exposes reasoning steps, showing not just the input and output but the intermediate thinking process.'
    },
    {
      difficulty: 'medium',
      question: 'According to the example selection strategies, why should you include "near-misses" in your examples?',
      options: {
        A: 'To confuse the model and test its limits',
        B: 'To establish precise boundaries for classification',
        C: 'To reduce token count',
        D: 'To demonstrate common errors'
      },
      correct: 'B',
      hint: 'Think about clarifying boundaries between categories',
      explanation: 'Including near-misses helps establish precise boundaries by showing the model examples that are close to but not quite in a category, helping it understand subtle distinctions.'
    },
    {
      difficulty: 'hard',
      question: 'Why is the "Input-Output Pairs" template particularly good for structured data?',
      options: {
        A: 'It uses less tokens than other templates',
        B: 'It has clear demarcation between inputs and outputs',
        C: 'It automatically formats JSON responses',
        D: 'It requires fewer examples'
      },
      correct: 'B',
      hint: 'Consider the explicit separation of components',
      explanation: 'The Input-Output Pairs template provides clear demarcation between inputs and outputs, making it ideal for structured data where clear separation and formatting are important.'
    }
  ]}
/>

## Measuring Molecular Efficiency

As context size grows, so does token count. Let's empirically measure the trade-off:

```
                   [Accuracy]
                       ▲
                       │                                    ● 4-shot
                       │                           ● 3-shot
                       │                              
                       │                   ● 2-shot 
                       │              
                       │           
                       │           ● 1-shot 
                       │      
                       │
                       │  
                       │   ● 0-shot
                       └─────────────────────────────────────────────────►
                                [Tokens]
```

The key insight: **diminishing returns**. Each additional example costs tokens but yields less improvement than the previous one.

## Finding the Molecular Sweet Spot

For most tasks, there's an optimal number of examples that balances quality and token efficiency:

```
┌─────────────────────────────────────────────────────────────────┐
│ EXAMPLE COUNT HEURISTICS BY TASK TYPE                           │
├───────────────────────────┬─────────────────────────────────────┤
│ Classification            │ 1-3 examples per class              │
├───────────────────────────┼─────────────────────────────────────┤
│ Generation                │ 2-5 examples                        │
├───────────────────────────┼─────────────────────────────────────┤
│ Structured Extraction     │ 2-4 examples covering all fields    │
├───────────────────────────┼─────────────────────────────────────┤
│ Reasoning                 │ 2-3 examples with thinking steps    │
├───────────────────────────┼─────────────────────────────────────┤
│ Translation               │ 3-5 examples with varying complexity│
└───────────────────────────┴─────────────────────────────────────┘
```

## Dynamic Molecule Construction

Advanced context engineering involves dynamically selecting the most relevant examples for each input:

```
┌───────────────────────────────────────────────────────────────────┐
│                                                                   │
│   User Query                                                      │
│       │                                                           │
│       ▼                                                           │
│  ┌─────────────┐      ┌─────────────────┐                         │
│  │ Query       │      │                 │                         │
│  │ Analysis    │─────▶│ Example         │                         │
│  │             │      │ Database        │                         │
│  └─────────────┘      │                 │                         │
│                       └─────────────────┘                         │
│                              │                                    │
│                              │ Retrieve most                      │
│                              │ similar examples                   │
│                              ▼                                    │
│                       ┌─────────────────┐                         │
│                       │ Dynamic         │                         │
│                       │ Molecular       │                         │
│                       │ Context         │                         │
│                       └─────────────────┘                         │
│                              │                                    │
│                              │                                    │
│                              ▼                                    │
│                       ┌─────────────────┐                         │
│                       │                 │                         │
│                       │ LLM             │                         │
│                       │                 │                         │
│                       └─────────────────┘                         │
│                                                                   │
└───────────────────────────────────────────────────────────────────┘
```

This approach:
1. Analyzes the user query
2. Retrieves the most relevant examples
3. Constructs a tailored molecular context
4. Sends the optimized context to the LLM

<QuizEmbed 
  moduleId="module-2" 
  section="efficiency"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'What is the key insight about adding more examples to a molecular prompt?',
      options: {
        A: 'More examples always lead to better results',
        B: 'Examples have diminishing returns - each additional example yields less improvement',
        C: 'Examples should be unlimited for best performance',
        D: 'The number of examples does not affect performance'
      },
      correct: 'B',
      hint: 'Look at the accuracy vs. tokens graph',
      explanation: 'The key insight is diminishing returns: each additional example costs tokens but yields less improvement than the previous one, creating a trade-off between quality and efficiency.'
    },
    {
      difficulty: 'medium',
      question: 'For classification tasks, what is the recommended number of examples per class?',
      options: {
        A: '1-3 examples per class',
        B: '3-5 examples per class',
        C: '5-10 examples per class',
        D: '10+ examples per class'
      },
      correct: 'A',
      hint: 'Check the "Example Count Heuristics by Task Type" table',
      explanation: 'The content recommends 1-3 examples per class for classification tasks, balancing effectiveness with token efficiency.'
    },
    {
      difficulty: 'hard',
      question: 'In dynamic molecule construction, what is the primary advantage over static examples?',
      options: {
        A: 'It uses fewer tokens overall',
        B: 'It retrieves and uses the most relevant examples for each specific input',
        C: 'It eliminates the need for an example database',
        D: 'It automatically generates new examples'
      },
      correct: 'B',
      hint: 'Consider how dynamic construction adapts to each query',
      explanation: 'Dynamic molecule construction analyzes each query and retrieves the most relevant examples from a database, creating a tailored molecular context optimized for that specific input rather than using the same static examples for all queries.'
    }
  ]}
/>

## Putting It Into Practice: A Simple Implementation

Here's a Python function that constructs a molecular context from examples:

```python
def create_molecular_context(instruction, examples, new_input, 
                            format_type="input-output"):
    """
    Construct a molecular context from examples.
    
    Args:
        instruction (str): The task instruction
        examples (List[Dict]): List of example input/output pairs
        new_input (str): The new input to process
        format_type (str): Template type (input-output, chain-of-thought)
    
    Returns:
        str: The complete molecular context
    """
    context = f"{instruction}\n\n"
    
    # Add examples based on format type
    if format_type == "input-output":
        for example in examples:
            context += f"Input: {example['input']}\n"
            context += f"Output: {example['output']}\n\n"
    elif format_type == "chain-of-thought":
        for example in examples:
            context += f"Input: {example['input']}\n"
            context += f"Thinking: {example['thinking']}\n"
            context += f"Output: {example['output']}\n\n"
    
    # Add the new input
    context += f"Input: {new_input}\nOutput:"
    
    return context
```

## Key Takeaways

1. **Molecular contexts** combine instructions with examples to improve LLM performance
2. **Few-shot learning** lets models recognize and continue patterns
3. **Template structure** matters; different formats work better for different tasks
4. **Example selection** is a science; diversity, edge cases, and ordering all matter
5. **Diminishing returns** exist; each additional example costs tokens with decreasing benefit
6. **Dynamic construction** can optimize the context for each specific input

## Exercises for Practice

1. Take a simple classification task and measure performance with 0, 1, 3, and 5 examples
2. Compare different template structures on the same task
3. Implement dynamic example selection based on similarity to the new input
4. Find the "minimum viable molecule" for a task you care about

## Deeper Dive: Prompt Engineering vs. Context Engineering

Prompt engineering focuses on crafting the perfect instruction. Context engineering encompasses that and more:

```
┌─────────────────────────────────────────────────────────────────────┐
│ CONTEXT ENGINEERING LAYERS                                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   ┌─────────────────┐                                               │
│   │ State & Memory  │  Conversation history, persistent variables   │
│   └─────────────────┘                                               │
│           ▲                                                         │
│           │                                                         │
│   ┌─────────────────┐                                               │
│   │ Retrieved Data  │  RAG, tool outputs, external knowledge        │
│   └─────────────────┘                                               │
│           ▲                                                         │
│           │                                                         │
│   ┌─────────────────┐                                               │
│   │ Examples        │  Few-shot learning, demonstrations            │
│   └─────────────────┘                                               │
│           ▲                                                         │
│           │                                                         │
│   ┌─────────────────┐                                               │
│   │ Instructions    │  Prompts, system messages, constraints        │
│   └─────────────────┘                                               │
│           ▲                                                         │
│           │                                                         │
│   ┌─────────────────┐                                               │
│   │ Model Behavior  │  Training data, alignments, capabilities      │
│   └─────────────────┘                                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

Context engineering gives you control over more of these layers, leading to more powerful applications.

---

# Part 2: Cells - Adding Memory and State

> "We are our memory, we are that chimerical museum of shifting shapes, that pile of broken mirrors." — Jorge Luis Borges

## From Molecules to Cells

We've explored **atoms** (single instructions) and **molecules** (instructions with examples). Now we ascend to **cells** — context structures with **memory** that persist across multiple interactions.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  CELL = [INSTRUCTIONS] + [EXAMPLES] + [MEMORY/STATE] + [CURRENT INPUT]      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

Like a biological cell that maintains its internal state while interacting with its environment, our context "cells" preserve information across multiple exchanges with the LLM.

## The Memory Problem

By default, LLMs have no memory. Each request is processed independently:

```
┌───────────────────────┐      ┌───────────────────────┐
│ Request 1             │      │ Request 2             │
├───────────────────────┤      ├───────────────────────┤
│ "My name is Alex."    │      │ "What's my name?"     │
│                       │      │                       │
│                       │      │                       │
└───────────────────────┘      └───────────────────────┘
          │                              │
          ▼                              ▼
┌───────────────────────┐      ┌───────────────────────┐
│ Response 1            │      │ Response 2            │
├───────────────────────┤      ├───────────────────────┤
│ "Hello Alex, nice     │      │ "I don't have access  │
│  to meet you."        │      │  to previous          │
│                       │      │  conversations..."    │
└───────────────────────┘      └───────────────────────┘
```

Without memory, the LLM forgets information from previous interactions, creating a disjointed, frustrating user experience.

<QuizEmbed 
  moduleId="module-2" 
  section="memory-basics"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'What is the primary difference between a "molecule" and a "cell" in context engineering?',
      options: {
        A: 'Cells use more examples than molecules',
        B: 'Cells include memory/state that persists across multiple interactions',
        C: 'Molecules are more complex than cells',
        D: 'Cells can only be used with specific LLMs'
      },
      correct: 'B',
      hint: 'Consider what makes cells able to maintain continuity',
      explanation: 'The key difference is that cells include memory/state that persists across multiple interactions, while molecules only contain instructions and examples for a single interaction.'
    },
    {
      difficulty: 'medium',
      question: 'Why do LLMs by default have no memory between requests?',
      options: {
        A: 'To save computational resources',
        B: 'Each request is processed independently without context from previous interactions',
        C: 'Memory was intentionally removed for privacy reasons',
        D: 'LLMs are incapable of processing sequential information'
      },
      correct: 'B',
      hint: 'Think about how LLMs process individual requests',
      explanation: 'LLMs process each request independently by default. Without explicitly including conversation history in the context, the model has no access to information from previous interactions.'
    },
    {
      difficulty: 'hard',
      question: 'The equation CELL = [INSTRUCTIONS] + [EXAMPLES] + [MEMORY/STATE] + [CURRENT INPUT] shows cells build upon molecules by adding what component?',
      options: {
        A: 'Examples and instructions',
        B: 'Current input processing',
        C: 'Memory/State that persists across interactions',
        D: 'Multiple LLM instances'
      },
      correct: 'C',
      hint: 'Compare this equation to the molecule equation',
      explanation: 'The cell equation adds [MEMORY/STATE] to the molecular structure, enabling persistence of information across multiple interactions beyond the static examples in molecules.'
    }
  ]}
/>

## The Cell Solution: Conversation Memory

The simplest cell structure adds conversation history to the context:

```
┌───────────────────────────────────────────────────────────────────────┐
│                                                                       │
│  SYSTEM PROMPT: "You are a helpful assistant..."                      │
│                                                                       │
│  CONVERSATION HISTORY:                                                │
│  User: "My name is Alex."                                             │
│  Assistant: "Hello Alex, nice to meet you."                           │
│                                                                       │
│  CURRENT INPUT: "What's my name?"                                     │
│                                                                       │
└───────────────────────────────────────────────────────────────────────┘
```

Now the LLM can access previous exchanges and maintain continuity.

## The Memory Token Budget Problem

As conversations grow, context windows fill up. We need memory management strategies:

```
          [Context Window Tokens]
          ┌─────────────────────────────────────────────┐
          │                                             │
Turn 1    │ System Instructions       User Input 1      │
          │                                             │
          ├─────────────────────────────────────────────┤
          │                                             │
Turn 2    │ System    History 1       User Input 2      │
          │                                             │
          ├─────────────────────────────────────────────┤
          │                                             │
Turn 3    │ Sys  History 1  History 2  User Input 3     │
          │                                             │
          ├─────────────────────────────────────────────┤
          │                                             │
Turn 4    │ S  History 1-3             User Input 4     │
          │                                             │
          ├─────────────────────────────────────────────┤
          │                                             │
Turn 5    │ History 2-4                User Input 5     │
          │                                             │
          └─────────────────────────────────────────────┘
                                       ▲
                                       │
                        Eventually, something has to go
```

## Memory Management Strategies

Several strategies help optimize the use of limited context windows:

```
┌───────────────────────────────────────────────────────────────────┐
│ MEMORY MANAGEMENT STRATEGIES                                      │
├────────────────────┬──────────────────────────────────────────────┤
│ Windowing          │ Keep only the most recent N turns            │
├────────────────────┼──────────────────────────────────────────────┤
│ Summarization      │ Compress older turns into summaries          │
├────────────────────┼──────────────────────────────────────────────┤
│ Key-Value Storage  │ Extract and store important facts separately │
├────────────────────┼──────────────────────────────────────────────┤
│ Priority Pruning   │ Remove less important turns first            │
├────────────────────┼──────────────────────────────────────────────┤
│ Semantic Chunking  │ Group related exchanges together             │
└────────────────────┴──────────────────────────────────────────────┘
```

<QuizEmbed 
  moduleId="module-2" 
  section="memory-strategies"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'What is the "windowing" memory management strategy?',
      options: {
        A: 'Storing all conversation history in external databases',
        B: 'Keeping only the most recent N conversation turns',
        C: 'Summarizing all previous conversations',
        D: 'Randomly selecting which turns to keep'
      },
      correct: 'B',
      hint: 'Think about a sliding window over conversation history',
      explanation: 'Windowing keeps only the most recent N turns of conversation, creating a sliding window that moves forward with each new exchange while dropping the oldest turns.'
    },
    {
      difficulty: 'medium',
      question: 'What is the main advantage of summarization over windowing for memory management?',
      options: {
        A: 'Summarization uses fewer tokens',
        B: 'Summarization preserves key information from older turns while reducing token count',
        C: 'Summarization is easier to implement',
        D: 'Summarization works with any LLM'
      },
      correct: 'B',
      hint: 'Consider what happens to old information with each strategy',
      explanation: 'Summarization compresses older turns into summaries, preserving key information while reducing token count, whereas windowing completely drops old turns and loses that information.'
    },
    {
      difficulty: 'hard',
      question: 'In the "Key-Value Storage" strategy, what is the primary benefit over keeping full conversation history?',
      options: {
        A: 'It stores more information than full history',
        B: 'It provides precise control over what information is retained in a structured format',
        C: 'It requires no memory management',
        D: 'It automatically generates summaries'
      },
      correct: 'B',
      hint: 'Think about structured vs. unstructured storage',
      explanation: 'Key-Value Storage extracts and stores important facts in a structured format, providing precise control over what information is retained and how it\'s accessed, rather than keeping verbose conversation history.'
    }
  ]}
/>

## Windowing: The Sliding Context

The simplest memory management approach keeps only the most recent conversation turns:

```
                    ┌───────────────────────────┐
Turn 1              │ System + Turn 1           │
                    └───────────────────────────┘
                              │
                              ▼
                    ┌───────────────────────────┐
Turn 2              │ System + Turn 1-2         │
                    └───────────────────────────┘
                              │
                              ▼
                    ┌───────────────────────────┐
Turn 3              │ System + Turn 1-3         │
                    └───────────────────────────┘
                              │
                              ▼
                    ┌───────────────────────────┐
Turn 4              │ System + Turn 2-4         │ ← Turn 1 dropped
                    └───────────────────────────┘
                              │
                              ▼
                    ┌───────────────────────────┐
Turn 5              │ System + Turn 3-5         │ ← Turn 2 dropped
                    └───────────────────────────┘
```

This approach is simple but forgets information from earlier turns.

## Summarization: Compressing Memory

A more sophisticated approach compresses older turns into summaries:

```
                    ┌────────────────────────────────────────────┐
Turn 1-3            │ System + Turn 1-3                          │
                    └────────────────────────────────────────────┘
                                       │
                                       ▼
                    ┌────────────────────────────────────────────┐
Turn 4              │ System + Summary(Turn 1-2) + Turn 3-4      │
                    └────────────────────────────────────────────┘
                                       │
                                       ▼
                    ┌────────────────────────────────────────────┐
Turn 5              │ System + Summary(Turn 1-3) + Turn 4-5      │
                    └────────────────────────────────────────────┘
```

Summarization preserves key information while reducing token count.

## Key-Value Memory: Structured State

For more control, we can extract and store important facts in a structured format:

```
┌─────────────────────────────────────────────────────────────────────┐
│ CONTEXT WINDOW                                                      │
│                                                                     │
│  SYSTEM PROMPT: "You are a helpful assistant..."                    │
│                                                                     │
│  MEMORY:                                                            │
│  {                                                                  │
│    "user_name": "Alex",                                             │
│    "favorite_color": "blue",                                        │
│    "location": "Toronto",                                           │
│    "last_topic": "vacation plans"                                   │
│  }                                                                  │
│                                                                     │
│  RECENT CONVERSATION:                                               │
│  User: "What activities would you recommend?"                       │
│  Assistant: "Given your location in Toronto and interest in..."     │
│                                                                     │
│  CURRENT INPUT: "How about something indoors? It's cold."           │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

This structured approach allows precise control over what information is retained.

## Beyond Conversation: Stateful Applications

Cells enable far more than just coherent conversations. They allow stateful applications where the LLM:

1. Remembers previous interactions
2. Updates and maintains variables
3. Tracks progress through multi-step processes
4. Builds on previous outputs

Let's explore a simple calculator example:

```
┌─────────────────────────────────────────────────────────────────────┐
│ STATEFUL CALCULATOR                                                 │
│                                                                     │
│ SYSTEM: "You are a calculator assistant that maintains a running    │
│          total. Follow the user's math operations step by step."    │
│                                                                     │
│ STATE: { "current_value": 0 }                                       │
│                                                                     │
│ User: "Start with 5"                                                │
│ Assistant: "Starting with 5. Current value is 5."                   │
│ STATE: { "current_value": 5 }                                       │
│                                                                     │
│ User: "Multiply by 3"                                               │
│ Assistant: "5 × 3 = 15. Current value is 15."                       │
│ STATE: { "current_value": 15 }                                      │
│                                                                     │
│ User: "Add 7"                                                       │
│ Assistant: "15 + 7 = 22. Current value is 22."                      │
│ STATE: { "current_value": 22 }                                      │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

The state variable persists across turns, enabling continuous calculations.

<QuizEmbed 
  moduleId="module-2" 
  section="stateful-apps"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'What makes an application "stateful" in the context of LLM interactions?',
      options: {
        A: 'It uses multiple LLMs',
        B: 'It maintains variables and information that persist across interactions',
        C: 'It only works with specific programming languages',
        D: 'It stores everything in external databases'
      },
      correct: 'B',
      hint: 'Think about what persists between interactions',
      explanation: 'A stateful application maintains variables and information that persist across multiple interactions, enabling the LLM to remember, update, and build upon previous exchanges.'
    },
    {
      difficulty: 'medium',
      question: 'In the stateful calculator example, what enables the LLM to maintain the running total?',
      options: {
        A: 'The LLM has built-in memory',
        B: 'The STATE variable that persists and updates across turns',
        C: 'External database storage',
        D: 'Multiple concurrent LLM instances'
      },
      correct: 'B',
      hint: 'Look at how the current_value is tracked',
      explanation: 'The STATE variable with "current_value" persists and updates across turns, being included in the context for each interaction to maintain the running total.'
    },
    {
      difficulty: 'hard',
      question: 'What are the four capabilities that cells enable for stateful applications?',
      options: {
        A: 'Faster processing, better accuracy, lower cost, easier implementation',
        B: 'Remembers interactions, updates variables, tracks progress, builds on previous outputs',
        C: 'Multiple models, distributed processing, cloud storage, real-time updates',
        D: 'Classification, generation, reasoning, translation'
      },
      correct: 'B',
      hint: 'Review the numbered list in "Beyond Conversation: Stateful Applications"',
      explanation: 'The content lists four key capabilities: 1) Remembers previous interactions, 2) Updates and maintains variables, 3) Tracks progress through multi-step processes, 4) Builds on previous outputs.'
    }
  ]}
/>

## Long-Term Memory: Beyond the Context Window

For truly persistent memory, we need external storage:

```
┌──────────────────────────────────────────────────────────────────────────┐
│                                                                          │
│   User Input                                                             │
│       │                                                                  │
│       ▼                                                                  │
│  ┌─────────────┐                                                         │
│  │ Extract     │                                                         │
│  │ Key Info    │                                                         │
│  └─────────────┘                                                         │
│       │                                                                  │
│       ▼                                                                  │
│  ┌─────────────┐      ┌────────────────────┐                             │
│  │ Update      │◄─────┤ External Memory    │                             │
│  │ Memory      │      │ (Vector DB,        │                             │
│  │             │─────►│  Document DB, etc) │                             │
│  └─────────────┘      └────────────────────┘                             │
│       │                        ▲                                         │
│       │                        │                                         │
│       ▼                        │                                         │
│  ┌─────────────┐      ┌────────────────────┐                             │
│  │ Construct   │      │ Retrieve Relevant  │                             │
│  │ Context     │◄─────┤ Memory             │                             │
│  │             │      │                    │                             │
│  └─────────────┘      └────────────────────┘                             │
│       │                                                                  │
│       ▼                                                                  │
│  ┌─────────────┐                                                         │
│  │             │                                                         │
│  │ LLM         │                                                         │
│  │             │                                                         │
│  └─────────────┘                                                         │
│       │                                                                  │
│       ▼                                                                  │
│   Response                                                               │
│                                                                          │
└──────────────────────────────────────────────────────────────────────────┘
```

This architecture enables potentially unlimited memory by:
1. Extracting key information from conversations
2. Storing it in external databases
3. Retrieving relevant context when needed
4. Incorporating that context into the prompt

## Cell Implementation: A Memory Manager

Here's a Python class that implements basic memory management:

```python
class ContextCell:
    """A context cell that maintains memory across interactions."""
    
    def __init__(self, system_prompt, max_turns=10, memory_strategy="window"):
        """
        Initialize the context cell.
        
        Args:
            system_prompt (str): The system instructions
            max_turns (int): Maximum conversation turns to keep
            memory_strategy (str): 'window', 'summarize', or 'key_value'
        """
        self.system_prompt = system_prompt
        self.max_turns = max_turns
        self.memory_strategy = memory_strategy
        self.conversation_history = []
        self.key_value_store = {}
        
    def add_exchange(self, user_input, assistant_response):
        """Add a conversation exchange to history."""
        self.conversation_history.append({
            "user": user_input,
            "assistant": assistant_response
        })
        
        # Apply memory management if needed
        if len(self.conversation_history) > self.max_turns:
            self._manage_memory()
    
    def extract_info(self, key, value):
        """Store important information in key-value store."""
        self.key_value_store[key] = value
    
    def _manage_memory(self):
        """Apply the selected memory management strategy."""
        if self.memory_strategy == "window":
            # Keep only the most recent turns
            self.conversation_history = self.conversation_history[-self.max_turns:]
        
        elif self.memory_strategy == "summarize":
            # Summarize older turns (would use an LLM in practice)
            to_summarize = self.conversation_history[:-self.max_turns + 1]
            summary = self._create_summary(to_summarize)
            
            # Replace old turns with summary
            self.conversation_history = [{"summary": summary}] + \
                                       self.conversation_history[-(self.max_turns-1):]
    
    def _create_summary(self, exchanges):
        """Create a summary of conversation exchanges."""
        # In practice, this would call an LLM to create the summary
        # For this example, we'll use a placeholder
        return f"Summary of {len(exchanges)} previous exchanges"
    
    def build_context(self, current_input):
        """Build the full context for the next LLM call."""
        context = f"{self.system_prompt}\n\n"
        
        # Add key-value memory if we have any
        if self.key_value_store:
            context += "MEMORY:\n"
            for key, value in self.key_value_store.items():
                context += f"{key}: {value}\n"
            context += "\n"
        
        # Add conversation history
        if self.conversation_history:
            context += "CONVERSATION HISTORY:\n"
            for exchange in self.conversation_history:
                if "summary" in exchange:
                    context += f"[Previous exchanges: {exchange['summary']}]\n\n"
                else:
                    context += f"User: {exchange['user']}\n"
                    context += f"Assistant: {exchange['assistant']}\n\n"
        
        # Add current input
        context += f"User: {current_input}\nAssistant:"
        
        return context
```

<QuizEmbed 
  moduleId="module-2" 
  section="implementation"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'In the ContextCell class, what does the max_turns parameter control?',
      options: {
        A: 'The maximum length of each message',
        B: 'The maximum number of conversation turns to keep in memory',
        C: 'The maximum number of examples to use',
        D: 'The maximum token count'
      },
      correct: 'B',
      hint: 'Look at the __init__ method documentation',
      explanation: 'The max_turns parameter controls the maximum number of conversation turns to keep in memory before memory management strategies are applied.'
    },
    {
      difficulty: 'medium',
      question: 'What does the extract_info() method in the ContextCell class do?',
      options: {
        A: 'Extracts text from external files',
        B: 'Stores important information in a key-value store for later retrieval',
        C: 'Summarizes conversation history',
        D: 'Removes old conversation turns'
      },
      correct: 'B',
      hint: 'Consider the structured memory approach',
      explanation: 'The extract_info() method stores important information in the key_value_store dictionary, allowing structured facts to be retained and accessed separately from conversation history.'
    },
    {
      difficulty: 'hard',
      question: 'In the build_context() method, what order are components added to construct the full context?',
      options: {
        A: 'Current input → System prompt → Memory → History',
        B: 'System prompt → Key-value memory → Conversation history → Current input',
        C: 'Memory → System prompt → History → Current input',
        D: 'History → Memory → System prompt → Current input'
      },
      correct: 'B',
      hint: 'Follow the method implementation step by step',
      explanation: 'The build_context() method constructs context in this order: 1) System prompt, 2) Key-value memory (if any), 3) Conversation history, 4) Current input with "User:" prefix and "Assistant:" prompt.'
    }
  ]}
/>

## Measuring Cell Efficiency

As with molecules, measuring efficiency is crucial for cells:

```
┌─────────────────────────────────────────────────────────────────┐
│ MEMORY STRATEGY COMPARISON                                      │
├──────────────────┬──────────────┬─────────────┬─────────────────┤
│ Strategy         │ Token Usage  │ Information │ Implementation  │
│                  │              │ Retention   │ Complexity      │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ No Memory        │ Lowest       │ None        │ Trivial         │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ Full History     │ Highest      │ Complete    │ Trivial         │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ Windowing        │ Controlled   │ Recent Only │ Easy            │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ Summarization    │ Moderate     │ Good        │ Moderate        │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ Key-Value Store  │ Low          │ Selective   │ Moderate        │
├──────────────────┼──────────────┼─────────────┼─────────────────┤
│ External Store   │ Very Low     │ Extensive   │ Complex         │
└──────────────────┴──────────────┴─────────────┴─────────────────┘
```

Different strategies optimize for different priorities. Choosing the right approach depends on your specific application needs.

## Advanced Techniques: Memory Orchestration

For sophisticated applications, multiple memory systems can work together:

```
┌─────────────────────────────────────────────────────────────────────┐
│                      MEMORY ORCHESTRATION                           │
│                                                                     │
│  ┌─────────────────┐    ┌─────────────────┐   ┌─────────────────┐   │
│  │                 │    │                 │   │                 │   │
│  │ Short-term      │    │ Working         │   │ Long-term       │   │
│  │ Memory          │    │ Memory          │   │ Memory          │   │
│  │                 │    │                 │   │                 │   │
│  │ • Recent turns  │    │ • Current task  │   │ • User profile  │   │
│  │ • Immediate     │    │ • Active        │   │ • Historical    │   │
│  │   context       │    │   variables     │   │   facts         │   │
│  │ • Last few      │    │ • Task progress │   │ • Learned       │   │
│  │   exchanges     │    │ • Mid-task      │   │   preferences   │   │
│  │                 │    │   state         │   │                 │   │
│  └─────────────────┘    └─────────────────┘   └─────────────────┘   │
│         ▲ ▼                   ▲ ▼                   ▲ ▼             │
│         │ │                   │ │                   │ │             │
│  ┌──────┘ └───────────────────┘ └───────────────────┘ └──────┐      │
│  │                                                           │      │
│  │                    Memory Manager                         │      │
│  │                                                           │      │
│  └───────────────────────────────┬───────────────────────────┘      │
│                                  │                                  │
│                                  ▼                                  │
│                        ┌─────────────────┐                          │
│                        │                 │                          │
│                        │   Context       │                          │
│                        │   Builder       │                          │
│                        │                 │                          │
│                        └─────────────────┘                          │
│                                  │                                  │
│                                  ▼                                  │
│                        ┌─────────────────┐                          │
│                        │                 │                          │
│                        │      LLM        │                          │
│                        │                 │                          │
│                        └─────────────────┘                          │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

This architecture mirrors human memory systems, with:
- **Short-term memory**: Recent conversation turns
- **Working memory**: Active task state and variables
- **Long-term memory**: Persistent user information and preferences

The memory manager orchestrates these systems, deciding what information to include in each context.

<QuizEmbed 
  moduleId="module-2" 
  section="orchestration"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'In memory orchestration, what type of information is stored in "Short-term memory"?',
      options: {
        A: 'User profile and preferences',
        B: 'Recent conversation turns and immediate context',
        C: 'Current task progress and variables',
        D: 'Historical facts from all conversations'
      },
      correct: 'B',
      hint: 'Think about what information is most immediate',
      explanation: 'Short-term memory stores recent conversation turns and immediate context, mirroring how human short-term memory works with recently accessed information.'
    },
    {
      difficulty: 'medium',
      question: 'How does memory orchestration architecture mirror human memory systems?',
      options: {
        A: 'By using neural networks',
        B: 'By having separate short-term, working, and long-term memory systems',
        C: 'By forgetting information randomly',
        D: 'By storing everything permanently'
      },
      correct: 'B',
      hint: 'Consider the three types of memory shown in the diagram',
      explanation: 'Memory orchestration mirrors human cognitive architecture by having three separate memory systems: short-term (recent context), working (active task state), and long-term (persistent information).'
    },
    {
      difficulty: 'hard',
      question: 'What is the role of the "Memory Manager" in the memory orchestration architecture?',
      options: {
        A: 'It stores all conversation history',
        B: 'It decides what information from each memory system to include in each context',
        C: 'It generates responses for the LLM',
        D: 'It replaces the need for a context builder'
      },
      correct: 'B',
      hint: 'Consider how different memory systems are coordinated',
      explanation: 'The Memory Manager orchestrates the three memory systems, deciding what information from short-term, working, and long-term memory should be included in the context for each interaction.'
    }
  ]}
/>

## Memory and Hallucination Reduction

One of the most valuable benefits of memory cells is reducing hallucinations:

```
┌─────────────────────────────────────────────────────────────────────┐
│ HALLUCINATION REDUCTION STRATEGIES                                  │
├─────────────────────────────────────────────────────────────────────┤
│ 1. Explicitly store facts extracted from previous exchanges         │
│ 2. Tag information with source/certainty levels                     │
│ 3. Include relevant facts in context when similar topics arise      │
│ 4. Detect and correct contradictions between memory and responses   │
│ 5. Periodically verify important facts through user confirmation    │
└─────────────────────────────────────────────────────────────────────┘
```

By grounding the LLM in consistent facts from memory, we improve reliability dramatically.

## Beyond Text: Structured State

Advanced cells maintain structured state beyond just text history:

```
┌─────────────────────────────────────────────────────────────────────┐
│ STRUCTURED STATE EXAMPLES                                           │
├─────────────────────────┬───────────────────────────────────────────┤
│ Progression State       │ {"step": 3, "completed_steps": [1, 2],    │
│                         │  "next_action": "validate_input"}         │
├─────────────────────────┼───────────────────────────────────────────┤
│ User Profile            │ {"name": "Alex", "preferences": {         │
│                         │  "communication_style": "concise",        │
│                         │  "expertise_level": "beginner"}}          │
├─────────────────────────┼───────────────────────────────────────────┤
│ Application State       │ {"current_view": "dashboard",             │
│                         │  "filters": ["active", "high_priority"],  │
│                         │  "sort_by": "deadline"}                   │
├─────────────────────────┼───────────────────────────────────────────┤
│ Environmental Context   │ {"location": "Toronto",                   │
│                         │  "weather": "snowing",                    │
│                         │  "time": "evening"}                       │
└─────────────────────────┴───────────────────────────────────────────┘
```

This structured approach allows precise control over the context and enables more sophisticated applications.

## Memory Feedback Loops

Sophisticated cells create feedback loops where the LLM helps manage its own memory:

```
┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  User: "I'm planning a trip to Japan next month."                   │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────────┐│
│  │ [INTERNAL MEMORY EXTRACTION]                                    ││
│  │ Important facts to remember:                                    ││
│  │ - User is planning a trip to Japan                              ││
│  │ - Trip is scheduled for next month                              ││
│  │ Confidence: High                                                ││
│  └─────────────────────────────────────────────────────────────────┘│
│                                                                     │
│  Assistant: "That's exciting! Japan is beautiful. Are you           │
│  interested in cities like Tokyo and Kyoto, or more rural areas?"   │
│                                                                     │
│  User: "Definitely Tokyo, and maybe Osaka too."                     │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────────┐│
│  │ [INTERNAL MEMORY UPDATE]                                        ││
│  │ Updated facts:                                                  ││
│  │ - User is planning a trip to Japan next month                   ││
│  │ - User is interested in Tokyo and Osaka                         ││
│  │ - User may not be interested in rural areas (confidence: medium)││
│  └─────────────────────────────────────────────────────────────────┘│
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

The LLM itself extracts and updates important information to remember, creating a self-improving memory system.

<QuizEmbed 
  moduleId="module-2" 
  section="advanced-concepts"
  quizzes={[
    {
      difficulty: 'simple',
      question: 'How do memory cells help reduce hallucinations?',
      options: {
        A: 'By using larger models',
        B: 'By grounding the LLM in consistent facts from memory',
        C: 'By limiting response length',
        D: 'By using multiple LLMs'
      },
      correct: 'B',
      hint: 'Consider how stored facts provide reliable information',
      explanation: 'Memory cells reduce hallucinations by grounding the LLM in consistent, stored facts from memory rather than forcing it to generate information without reliable context.'
    },
    {
      difficulty: 'medium',
      question: 'What is an example of "structured state" beyond text history?',
      options: {
        A: 'Longer conversation transcripts',
        B: 'JSON objects containing task progress, user profiles, or application state',
        C: 'Multiple text files',
        D: 'Compressed text summaries'
      },
      correct: 'B',
      hint: 'Look at the "Structured State Examples" table',
      explanation: 'Structured state uses JSON objects and other data structures to store specific information like task progress, user preferences, application state, etc., rather than just maintaining text conversation history.'
    },
    {
      difficulty: 'hard',
      question: 'In memory feedback loops, what creates a "self-improving memory system"?',
      options: {
        A: 'Automatic summarization of all conversations',
        B: 'The LLM itself extracts and updates important information to remember',
        C: 'External APIs that validate information',
        D: 'User manually tagging important information'
      },
      correct: 'B',
      hint: 'Consider who is doing the memory management',
      explanation: 'Memory feedback loops are "self-improving" because the LLM itself is responsible for extracting important facts, updating memory, and managing what should be remembered, creating an autonomous memory management system.'
    }
  ]}
/>

## Key Takeaways

1. **Memory cells** add state persistence across multiple interactions
2. **Token budget management** is crucial as conversations grow
3. **Memory strategies** include windowing, summarization, and key-value stores
4. **External memory** enables unlimited, persistent storage beyond the context window
5. **Structured state** enables sophisticated applications beyond simple conversations
6. **Memory orchestration** combines multiple memory systems for optimal performance
7. **Self-improving memory** uses the LLM to help manage its own memory

## Exercises for Practice

1. Implement a simple conversation memory system with windowing
2. Compare different memory strategies on the same extended conversation
3. Build a key-value store that extracts important facts from conversations
4. Experiment with using an LLM to summarize older conversation turns
5. Create a structured state manager for a specific application domain

## Next Steps

In the next section, we'll explore **organs** — multi-agent systems where multiple context cells work together to solve complex problems.

## Deeper Dive: Memory Abstractions

Memory can be organized in multiple layers of abstraction:

```
┌────────────────────────────────────────────────────────────────────┐
│ MEMORY ABSTRACTION LAYERS                                          │
├────────────────────────────────────────────────────────────────────┤
│                                                                    │
│   ┌─────────────────┐                                              │
│   │ Episodic Memory │  Specific conversation exchanges and events  │
│   └─────────────────┘                                              │
│           ▲                                                        │
│           │                                                        │
│   ┌─────────────────┐                                              │
│   │ Semantic Memory │  Facts, concepts, and structured knowledge   │
│   └─────────────────┘                                              │
│           ▲                                                        │
│           │                                                        │
│   ┌─────────────────┐                                              │
│   │ Conceptual      │  High-level patterns, preferences, goals     │
│   │ Memory          │                                              │
│   └─────────────────┘                                              │
│                                                                    │
└────────────────────────────────────────────────────────────────────┘
```

This layered approach allows the system to balance concrete details with high-level understanding of the interaction context.

---

## Attribution

**Content adapted from:** [Context-Engineering](https://github.com/davidkimai/Context-Engineering) by davidkimai

**Licensed under:** MIT License

**Original Source Files:**
- 00_foundations/02_molecules_few_shot.md
- 00_foundations/03_cells_memory.md

**Copyright:** © 2025 davidkimai  
**License:** MIT
